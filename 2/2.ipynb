{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#import winsound\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "classes = []\n",
    "f=open('/home/qwer/Downloads/ch7/coco.names.txt','r')\n",
    "classes=[line.strip() for line in f.readlines()]\n",
    "colors=np.random.uniform(0,255,size=(len(classes),3))\n",
    "\n",
    "yolo_model=cv2.dnn.readNet('/home/qwer/Downloads/ch7/yolov3.weights','/home/qwer/Downloads/ch7/yolov3.cfg') # 욜로 읽어오기\n",
    "layer_names=yolo_model.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in yolo_model.getUnconnectedOutLayers()]\n",
    "\n",
    "def process_video(): # 비디오에서 침입자 검출해 알리기\n",
    "   video=cv2.VideoCapture('nvarguscamerasrc ! video/x-raw(memory:NVMM), width=416, height=416, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv ! video/x-raw, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink', cv2.CAP_GSTREAMER)\n",
    "   while video.isOpened():\n",
    "       success,img=video.read()\n",
    "       if success:\n",
    "           height,width,channels=img.shape\n",
    "           blob=cv2.dnn.blobFromImage(img,1.0/256,(416,416),(0,0,0),swapRB=True,crop=False)\n",
    "\n",
    "           yolo_model.setInput(blob)\n",
    "           output=yolo_model.forward(output_layers)\n",
    "\n",
    "           class_ids,confidences,boxes=[],[],[]\n",
    "           for output in output:\n",
    "               for vec85 in output:\n",
    "                   scores=vec85[5:]\n",
    "                   class_id=np.argmax(scores)\n",
    "                   confidence=scores[class_id]\n",
    "                   if confidence>0.2: # 신뢰도가 50% 이상인 경우만 취함\n",
    "                       centerx,centery=int(vec85[0]*width),int(vec85[1]*height) # [0,1] 표현을 영상 크기로 변환\n",
    "                       w,h=int(vec85[2]*width),int(vec85[3]*height)\n",
    "                       x,y=int(centerx-w/2),int(centery-h/2)\n",
    "                       boxes.append([x,y,w,h])\n",
    "                       confidences.append(float(confidence))\n",
    "                       class_ids.append(class_id)\n",
    "                   \n",
    "           indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "                   \n",
    "           for i in range(len(boxes)):\n",
    "               if i in indexes:\n",
    "                   x,y,w,h=boxes[i]\n",
    "                   text=str(classes[class_ids[i]])+'%.3f'%confidences[i]\n",
    "                   cv2.rectangle(img,(x,y),(x+w,y+h),colors[class_ids[i]],2)\n",
    "                   cv2.putText(img,text,(x,y+30),cv2.FONT_HERSHEY_PLAIN,2,colors[class_ids[i]],2)\n",
    "                   \n",
    "\n",
    "           cv2.imshow('Object detection',img)\n",
    "\n",
    "           if 2 in class_ids:\n",
    "               print('차량이 접근중입니다.') #차\n",
    "               winsound.Beep(frequency=2000,duration=500)\n",
    "               \n",
    "           if 3 in class_ids:\n",
    "               print('오토바이가 접근중입니다.') #오토바이\n",
    "               winsound.Beep(frequency=2000,duration=500)\n",
    "               \n",
    "           if 5 in class_ids:\n",
    "               print('버스가 접근중') #버스\n",
    "               winsound.Beep(frequency=2000,duration=500)\n",
    "               \n",
    "           if 7 in class_ids:\n",
    "               print('트럭이 접근중') #트럭\n",
    "               winsound.Beep(frequency=2000,duration=500)\n",
    "               \n",
    "           if 1 in class_ids: # 자전거\n",
    "               print('자전거 접근중!!!')\n",
    "               winsound.Beep(frequency=2000,duration=500)\n",
    "               \n",
    "       key=cv2.waitKey(1) & 0xFF\n",
    "       if key==27: break\n",
    "\n",
    "   video.release()\n",
    "   cv2.destroyAllWindows()\n",
    "\n",
    "process_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
